{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c061a495-03b9-47dd-b688-1ace3699b83b",
   "metadata": {},
   "source": [
    "# Assignment-based Subjective Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce140ab0-2f2a-4d17-a590-22b1fe86e7a6",
   "metadata": {},
   "source": [
    "#### From your analysis of the categorical variables from the dataset, what could you infer about their effect on the dependent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d1ab8-d4d2-4707-959a-18f081ea4391",
   "metadata": {},
   "source": [
    "BoomBike demand doesn’t change whether day is working day or not. \n",
    "BoomBike demand in year 2019 is higher as compared to 2018. \n",
    "BoomBike demand in the fall is the highest. \n",
    "BoomBike demand takes a dip in spring. \n",
    "BoomBike demand is high if weather is clear or with mist cloudy while it is low when there is light rain or light snow. \n",
    "The demand of BoomBike is almost similar throughout the weekdays. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6be171-ab11-475f-8643-9f844436924c",
   "metadata": {},
   "source": [
    "### Why is it important to use drop_first=True during dummy variable creation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb126611-10e3-4076-afd7-39965b3b402e",
   "metadata": {},
   "source": [
    "It is important in order to achieve k-1 dummy variables as it can be used to delete extra column while creating dummy variables. •For Example: We have  rows: dteday, unfomated data format  it help to clean it make data consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001bd06-8554-4d6f-89c2-84e01011f1af",
   "metadata": {},
   "source": [
    "### Looking at the pair-plot among the numerical variables, which one has the highest correlation with the target variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f26cf-2b71-478d-b7af-8782e9ee4773",
   "metadata": {},
   "source": [
    "atemp and temp both have same correlation with target variable of 0.63 which is the highest among all numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e87ef-64d5-4080-9afd-ebbcb4217dce",
   "metadata": {},
   "source": [
    "### How did you validate the assumptions of Linear Regression after building the model on the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08ceb6-d34c-4cab-838c-be87fe30b85e",
   "metadata": {},
   "source": [
    "Normality of the error distribution (Normal distribution of error terms). Constant variance of the errors or Homoscedasticity. Less Multi-collinearity between features ( Low VIF) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7d214-f4f9-4428-ba76-4953d2152f16",
   "metadata": {},
   "source": [
    "### Based on the final model, which are the top 3 features contributing significantly towards explaining the demand of the shared bikes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643c4a8-1df7-45c3-ba7a-b85e23c40fbb",
   "metadata": {},
   "source": [
    "temp, sep rain fall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe9fc76-d8d0-4867-8328-f464882d3041",
   "metadata": {},
   "source": [
    "# General Subjective Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec1e13-899d-46cd-abfb-d77ca4515b79",
   "metadata": {},
   "source": [
    "### Explain the linear regression algorithm in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7a19f-1db8-41a1-97b0-432a3e2994fe",
   "metadata": {},
   "source": [
    "Linear regression assumes that there is a linear relationship between the dependent variable \n",
    "𝑌\n",
    "Y and the independent variable(s) \n",
    "𝑋\n",
    "X. This relationship can be represented by the equation:\n",
    "\n",
    "𝑌\n",
    "=\n",
    "𝛽\n",
    "0\n",
    "+\n",
    "𝛽\n",
    "1\n",
    "𝑋\n",
    "1\n",
    "+\n",
    "𝛽\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "+\n",
    "⋯\n",
    "+\n",
    "𝛽\n",
    "𝑛\n",
    "𝑋\n",
    "𝑛\n",
    "+\n",
    "𝜖\n",
    "Y=β \n",
    "0\n",
    "​\n",
    " +β \n",
    "1\n",
    "​\n",
    " X \n",
    "1\n",
    "​\n",
    " +β \n",
    "2\n",
    "​\n",
    " X \n",
    "2\n",
    "​\n",
    " +⋯+β \n",
    "n\n",
    "​\n",
    " X \n",
    "n\n",
    "​\n",
    " +ϵ\n",
    "\n",
    "where:\n",
    "\n",
    "𝑌\n",
    "Y is the dependent variable.\n",
    "𝑋\n",
    "1\n",
    ",\n",
    "𝑋\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝑋\n",
    "𝑛\n",
    "X \n",
    "1\n",
    "​\n",
    " ,X \n",
    "2\n",
    "​\n",
    " ,…,X \n",
    "n\n",
    "​\n",
    "  are the independent variables.\n",
    "𝛽\n",
    "0\n",
    "β \n",
    "0\n",
    "​\n",
    "  is the y-intercept (constant term).\n",
    "𝛽\n",
    "1\n",
    ",\n",
    "𝛽\n",
    "2\n",
    ",\n",
    "…\n",
    ",\n",
    "𝛽\n",
    "𝑛\n",
    "β \n",
    "1\n",
    "​\n",
    " ,β \n",
    "2\n",
    "​\n",
    " ,…,β \n",
    "n\n",
    "​\n",
    "  are the coefficients that represent the change in \n",
    "𝑌\n",
    "Y for a one-unit change in the corresponding \n",
    "𝑋\n",
    "X.\n",
    "𝜖\n",
    "ϵ is the error term (residual) that captures the deviations of the actual values from the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ee0fec-d19e-4b6e-af81-efffcabff34e",
   "metadata": {},
   "source": [
    "### Explain the Anscombe’s quartet in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428ae53-026a-4a1e-9f95-11053ae100af",
   "metadata": {},
   "source": [
    "Anscombe's quartet is a collection of four datasets that have nearly identical simple descriptive statistics, yet appear very different when graphed. This collection was created by the statistician Francis Anscombe in 1973 to demonstrate the importance of graphing data before analyzing it and to show that statistical properties do not provide a complete picture of the data. Each dataset consists of eleven (x, y) points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1337098-daf5-4d1a-96ba-8e272ddd768f",
   "metadata": {},
   "source": [
    "### What is Pearson’s R?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6632855c-2bc6-456e-99c3-b4ec26d076e3",
   "metadata": {},
   "source": [
    "Pearson's R, also known as the Pearson correlation coefficient, is a measure of the linear relationship between two variables. It quantifies the degree to which two variables are linearly related. The value of Pearson's R ranges from -1 to 1, where:\n",
    "\n",
    "𝑟\n",
    "=\n",
    "1\n",
    "r=1 indicates a perfect positive linear relationship,\n",
    "𝑟\n",
    "=\n",
    "−\n",
    "1\n",
    "r=−1 indicates a perfect negative linear relationship,\n",
    "𝑟\n",
    "=\n",
    "0\n",
    "r=0 indicates no linear relationship\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c26fc-1631-4d27-9d88-e45111ed2d16",
   "metadata": {},
   "source": [
    "### What is scaling? Why is scaling performed? What is the difference between normalized scaling and standardized scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269e7e3-a503-4476-9e21-27e798614ecb",
   "metadata": {},
   "source": [
    "Scaling is a preprocessing technique used in data analysis and machine learning to adjust the range of the features in the data. The primary goal of scaling is to ensure that different features contribute equally to the analysis and to improve the performance of machine learning algorithms. Some algorithms are sensitive to the scale of the data, and scaling can help achieve better convergence and results.\n",
    "Why is Scaling Performed?\n",
    "Equal Contribution of Features: Features with larger ranges can dominate the model training process, leading to biased results. Scaling ensures all features contribute equally.\n",
    "Improved Model Performance: Many machine learning algorithms (e.g., gradient descent-based algorithms, k-nearest neighbors, SVMs) perform better and converge faster when the data is scaled.\n",
    "Reduction of Numerical Instability: Scaling can help reduce numerical instability and improve the precision of calculations, especially for algorithms that involve matrix operations.\n",
    "Key Differences Between Normalization and Standardization\n",
    "Range:\n",
    "Normalization scales data to a specific range (e.g., [0, 1]).\n",
    "Standardization scales data to have a mean of 0 and a standard deviation of 1.\n",
    "Effect of Outliers:\n",
    "Normalization is more sensitive to outliers as they affect the min and max values.\n",
    "Standardization is less affected by outliers because it uses the mean and standard deviation.\n",
    "Use Cases:\n",
    "Normalization is suitable for data that is bounded and does not follow a normal distribution.\n",
    "Standardization is suitable for data that follows a normal distribution or when dealing with algorithms that assume normally distributed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf44af1-04eb-44c1-afa3-294dfa7b376a",
   "metadata": {},
   "source": [
    "### You might have observed that sometimes the value of VIF is infinite. Why does this happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c8f87-3a2f-47b1-a8a5-83399dd26618",
   "metadata": {},
   "source": [
    "coefficient is inflated due to multicollinearity with other independent variables in the model.\n",
    "\n",
    "The formula for VIF for a given predictor \n",
    "𝑋\n",
    "𝑖\n",
    "X \n",
    "i\n",
    "​\n",
    "  is:\n",
    "\n",
    "VIF\n",
    "(\n",
    "𝑋\n",
    "𝑖\n",
    ")\n",
    "=\n",
    "1\n",
    "1\n",
    "−\n",
    "𝑅\n",
    "𝑖\n",
    "2\n",
    "VIF(X \n",
    "i\n",
    "​\n",
    " )= \n",
    "1−R \n",
    "i\n",
    "2\n",
    "​\n",
    " \n",
    "1\n",
    "​\n",
    " \n",
    "\n",
    "where \n",
    "𝑅\n",
    "𝑖\n",
    "2\n",
    "R \n",
    "i\n",
    "2\n",
    "​\n",
    "  is the coefficient of determination obtained by regressing \n",
    "𝑋\n",
    "𝑖\n",
    "X \n",
    "i\n",
    "​\n",
    "  on all the other predictors.\n",
    "\n",
    "Why VIF Can Be Infinite\n",
    "The value of VIF can become infinite when the denominator of the VIF formula becomes zero, i.e., when \n",
    "𝑅\n",
    "𝑖\n",
    "2\n",
    "=\n",
    "1\n",
    "R \n",
    "i\n",
    "2\n",
    "​\n",
    " =1. This indicates perfect multicollinearity, which means that one predictor is a perfect linear combination of the other predictors. In other words, there is an exact linear relationship among some or all of the predictor variables.\n",
    "\n",
    "Reasons for Infinite VIF\n",
    "Perfect Multicollinearity:\n",
    "\n",
    "This occurs when one predictor variable can be perfectly predicted from the other predictor(s). For example, if \n",
    "𝑋\n",
    "1\n",
    "=\n",
    "2\n",
    "𝑋\n",
    "2\n",
    "X \n",
    "1\n",
    "​\n",
    " =2X \n",
    "2\n",
    "​\n",
    " , there is perfect multicollinearity between \n",
    "𝑋\n",
    "1\n",
    "X \n",
    "1\n",
    "​\n",
    "  and \n",
    "𝑋\n",
    "2\n",
    "X \n",
    "2\n",
    "​\n",
    " .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed5dbe-e178-4471-a107-4c45e7dc3d2a",
   "metadata": {},
   "source": [
    "### What is a Q-Q plot? Explain the use and importance of a Q-Q plot in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7399f-ec04-4bdb-8b2e-1a043a751703",
   "metadata": {},
   "source": [
    "A Q-Q plot, or Quantile-Quantile plot, is a graphical tool used to assess whether a dataset follows a particular theoretical distribution, such as the normal distribution. In the context of linear regression, Q-Q plots are primarily used to evaluate the assumption that the residuals (errors) of the regression model are normally distributed.\n",
    "\n",
    "Construction of a Q-Q Plot\n",
    "Sort Data: Sort the sample data in ascending order.\n",
    "Determine Theoretical Quantiles: Calculate the theoretical quantiles of the chosen distribution (e.g., normal distribution).\n",
    "Plot Points: Plot the sorted data values against the theoretical quantiles.\n",
    "Evaluate Linearity: Assess how closely the points follow a straight line. If the points lie approximately on the reference line (usually a 45-degree line), the data are consistent with the specified distribution.\n",
    "Use and Importance of a Q-Q Plot in Linear Regression\n",
    "1. Assessing Normality of Residuals\n",
    "Assumption Check: One of the key assumptions in linear regression is that the residuals are normally distributed. This assumption is important for the validity of hypothesis tests and confidence intervals.\n",
    "Visual Inspection: A Q-Q plot provides a visual method to check the normality assumption. If the residuals are normally distributed, the points in the Q-Q plot will lie approximately along the reference line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
